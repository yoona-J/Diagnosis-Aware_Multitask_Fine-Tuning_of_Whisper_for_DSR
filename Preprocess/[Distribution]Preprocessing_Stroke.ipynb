{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151e308-3b0c-4579-a903-b1a867d2fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962604c-071c-4eac-868c-bcd6a8a49f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8bec1-91a4-4321-9044-ac858cf91347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5413ffc-f32b-48d1-9d25-28dd5e1b9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"YOUR_ROOT\")\n",
    "\n",
    "Peripheral_Neuropathy_AUDIO = BASE_PATH / \"Training/audio_data/TS01/Peripheral_Neuropathy\"\n",
    "Peripheral_Neuropathy_LABEL = BASE_PATH / \"Training/label_data/TL01/Peripheral_Neuropathy\"\n",
    "\n",
    "Cerebral_Palsy_AUDIO = BASE_PATH / \"Validation/audio_data/VS01/Cerebral_Palsy_disease\"\n",
    "Cerebral_Palsy_LABEL = BASE_PATH / \"Validation/label_data/VL01/Cerebral_Palsy_disease\"\n",
    "\n",
    "Stroke_AUDIO = BASE_PATH / \"Validation/audio_data/VS01/Stroke\"\n",
    "Stroke_LABEL = BASE_PATH / \"Validation/label_data/VL01/Stroke\"\n",
    "\n",
    "OUTPUT_BASE = BASE_PATH / \"Preprocessed\"\n",
    "Peripheral_Neuropathy_OUTPUT = OUTPUT_BASE / \"Peripheral_Neuropathy_dataset\"\n",
    "Cerebral_Palsy_OUTPUT = OUTPUT_BASE / \"Cerebral_Palsy_dataset\"\n",
    "Stroke_OUTPUT = OUTPUT_BASE / \"Stroke_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02b1b1-3307-4fc1-a57d-1a0bdde21289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Peripheral_Neuropathy_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "Cerebral_Palsy_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "Stroke_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Peripheral_Neuropathy ‚Üí\", Peripheral_Neuropathy_OUTPUT)\n",
    "print(\"Cerebral_Palsy ‚Üí\", Cerebral_Palsy_OUTPUT)\n",
    "print(\"Stroke ‚Üí\", Stroke_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023ccc4-60b4-4e05-9c2a-17e60f702505",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Peripheral_Neuropathy]\")\n",
    "print(\"  üéß Audio_File_Count: \", len(os.listdir(Peripheral_Neuropathy_AUDIO)))\n",
    "print(\"  üè∑Ô∏è Label_File_Count: \", len(os.listdir(Peripheral_Neuropathy_LABEL)))\n",
    "\n",
    "print(\"[Cerebral_Palsy]\")\n",
    "print(\"  üéß Audio_File_Count: \", len(os.listdir(Cerebral_Palsy_AUDIO)))\n",
    "print(\"  üè∑Ô∏è Label_File_Count: \", len(os.listdir(Cerebral_Palsy_LABEL)))\n",
    "\n",
    "print(\"[Stroke]\")\n",
    "print(\"  üéß Audio_File_Count: \", len(os.listdir(Stroke_AUDIO)))\n",
    "print(\"  üè∑Ô∏è Label_File_Count: \", len(os.listdir(Stroke_LABEL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08b53b-601d-4ef6-b8b9-a92b2946686d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ba985-569b-4c21-9f46-ec704fd0a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import which\n",
    "print(\"ffmpeg location:\", which(\"ffmpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119eafe-0e85-449a-9788-ace6583d06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub.utils import db_to_float\n",
    "import itertools\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import IPython.display as ipd\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307139de-dbe8-4e45-92e3-ffcd4c62d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Audio Data Pre-proocessing\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "    \n",
    "# VAD\n",
    "def vad_segment_by_energy(audio_segment, frame_ms=500, silence_duration_sec=5, alpha=0.3):\n",
    "    frame_len = frame_ms\n",
    "    total_len = len(audio_segment)\n",
    "    energy_values = []\n",
    "\n",
    "    for i in range(0, total_len, frame_len):\n",
    "        frame = audio_segment[i:i+frame_len]\n",
    "        energy_values.append(frame.rms)\n",
    "\n",
    "    mean_energy = sum(energy_values) / len(energy_values)\n",
    "    threshold = mean_energy * alpha\n",
    "    silence_flags = [rms < threshold for rms in energy_values]\n",
    "\n",
    "    frame_duration_sec = frame_ms / 1000\n",
    "    min_silence_frames = int(silence_duration_sec / frame_duration_sec)\n",
    "\n",
    "    segments = []\n",
    "    is_silent = False\n",
    "    start = 0\n",
    "\n",
    "    for idx, silent in enumerate(silence_flags):\n",
    "        if not is_silent and silent:\n",
    "            silence_run = silence_flags[idx:idx+min_silence_frames]\n",
    "            if len(silence_run) == min_silence_frames and all(silence_run):\n",
    "                end = idx * frame_len\n",
    "                if end - start > 0:\n",
    "                    segments.append((start, end))\n",
    "                is_silent = True\n",
    "        elif is_silent and not silent:\n",
    "            start = idx * frame_len\n",
    "            is_silent = False\n",
    "\n",
    "    if not is_silent and start < total_len:\n",
    "        segments.append((start, total_len))\n",
    "\n",
    "    if not segments:\n",
    "        print(f\"VAD Failed\")\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Preprocessing\n",
    "def extract_vad_segments_for_all_files(Stroke_AUDIO, Stroke_OUTPUT, frame_ms=500, silence_duration_sec=5, alpha=0.3):\n",
    "    Stroke_audio_files = glob.glob(os.path.join(Stroke_AUDIO, \"*.wav\"))\n",
    "\n",
    "    if not os.path.exists(Stroke_OUTPUT):\n",
    "        os.makedirs(Stroke_OUTPUT)\n",
    "\n",
    "    for Stroke_audio_file in tqdm(Stroke_audio_files, desc=\"Is VAD processing...\"):\n",
    "        Stroke_base_filename = os.path.basename(Stroke_audio_file)\n",
    "    \n",
    "        if not os.path.exists(Stroke_audio_file):\n",
    "            print(f\"File not exist: {Stroke_audio_file}\")\n",
    "            continue\n",
    "            \n",
    "        # Person_code extraction (ex: ID-02-26-N-AJH-01-01-F-45-SU.wav ‚Üí AJH-01-01-F-45-SU)\n",
    "        match = re.match(r\"ID-\\d{2}-\\d{2}-N-(.+)\\.wav\", Stroke_base_filename)\n",
    "        if not match:\n",
    "            print(f\"Regular expression matching failed: {Stroke_base_filename}\")\n",
    "            continue\n",
    "\n",
    "        person_code = match.group(1)\n",
    "\n",
    "        # load audio\n",
    "        Stroke_audio = AudioSegment.from_file(Stroke_audio_file)\n",
    "\n",
    "        # Split Silence/non-Silence part\n",
    "        segments = vad_segment_by_energy(Stroke_audio, frame_ms, silence_duration_sec, alpha)\n",
    "\n",
    "        # Save Segment\n",
    "        for i, (start, end) in enumerate(segments):\n",
    "            segment = Stroke_audio[start:end]\n",
    "            Stroke_output_filename = f\"output_PN_{person_code}_{i}.wav\"\n",
    "            Stroke_output_path = os.path.join(Stroke_OUTPUT, Stroke_output_filename)\n",
    "            segment.export(Stroke_output_path, format=\"wav\")\n",
    "            print(f\"‚úÖ File {Stroke_base_filename} - Segment {i}: {start / 1000:.2f}s ~ {end / 1000:.2f}s ‚Üí {Stroke_output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc67df-e653-4861-8ed1-d3cde98a042d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_vad_segments_for_all_files(\n",
    "    Stroke_AUDIO=Stroke_AUDIO,\n",
    "    Stroke_OUTPUT=Stroke_OUTPUT,\n",
    "    frame_ms=500,\n",
    "    silence_duration_sec=5,\n",
    "    alpha=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e959b2-6d73-4bdb-a066-b79612b1e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT = os.path.join(Stroke_OUTPUT)\n",
    "\n",
    "print(\"Number of silence removal audio files: \", len(os.listdir(SEGMENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcfdcb-0f64-42de-87bc-a27f4d5ca840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Data pre-processing\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Stroke_df_list = []\n",
    "\n",
    "# Split and merge Text segments\n",
    "for i in range(len(os.listdir(Stroke_LABEL))):\n",
    "    # Load Script\n",
    "    Stroke_label_file = os.path.join(Stroke_LABEL, sorted(os.listdir(Stroke_LABEL))[i])\n",
    "    \n",
    "    Stroke_meta = pd.read_json(Stroke_label_file, orient='columns')\n",
    "    Stroke_transcript = str(Stroke_meta['Transcript'].iloc[0]).strip()\n",
    "\n",
    "    if \"/\" in Stroke_transcript:\n",
    "        Stroke_segments = Stroke_transcript.split(\"/\")\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "\n",
    "    elif re.search(r\"[\\.?!]\", Stroke_transcript):\n",
    "        Stroke_segments = re.split(r\"[\\.?!]\", Stroke_transcript)\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "    \n",
    "    else:\n",
    "        Stroke_segments = Stroke_transcript.split()\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "\n",
    "    # Convert DataFrame and add to list\n",
    "    if Stroke_segments:\n",
    "        Stroke_df = pd.DataFrame(Stroke_segments, columns=['text'])\n",
    "        Stroke_df_list.append(Stroke_df)\n",
    "\n",
    "Stroke_text_df = pd.concat(Stroke_df_list, axis=0, ignore_index=True)\n",
    "\n",
    "print(Stroke_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793583fb-4a80-43c3-858a-268dc5f3166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is a difference in the number of voice data and text data, the number of segments is estimated by comparing text and voice files.\n",
    "# Then, post-processing is performed on files that have differences between predicted and actual values.\n",
    "\n",
    "!pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65d955-ca16-4d60-9c27-fb8ca47f6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of the number of differences between voice-labeling\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_text_segment_count(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    transcript = str(data[\"Transcript\"]).strip()\n",
    "\n",
    "    if \"/\" in transcript:\n",
    "        segments = transcript.split(\"/\")\n",
    "    elif re.search(r\"[\\.?!]\", transcript):\n",
    "        segments = re.split(r\"[\\.?!]\", transcript)\n",
    "    else:\n",
    "        segments = transcript.split()\n",
    "\n",
    "    segments = [s.strip() for s in segments if s.strip()]\n",
    "    return len(segments)\n",
    "\n",
    "def count_audio_files(audio_folder, person_code):\n",
    "    prefix = f\"output_PN_{person_code}_\"\n",
    "    return len([\n",
    "        f for f in os.listdir(audio_folder)\n",
    "        if f.endswith(\".wav\") and f.startswith(prefix)\n",
    "    ])\n",
    "\n",
    "def analyze_by_count_only(audio_folder, label_folder, output_csv=\"review_targets_VAD_Stroke.csv\", threshold=0):\n",
    "    results = []\n",
    "\n",
    "    for json_file in sorted(os.listdir(label_folder)):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "    \n",
    "        json_path = os.path.join(label_folder, json_file)\n",
    "    \n",
    "        try:\n",
    "            match = re.match(r\"ID-\\d{2}-\\d{2}-N-(.+)\\.json\", json_file)\n",
    "            if not match:\n",
    "                raise ValueError(\"Fail extracting person_code\")\n",
    "            person_code = match.group(1)\n",
    "    \n",
    "            text_count = get_text_segment_count(json_path)\n",
    "            audio_count = count_audio_files(audio_folder, person_code)\n",
    "            gap = abs(text_count - audio_count)\n",
    "    \n",
    "            results.append({\n",
    "                \"file\": json_file,\n",
    "                \"person_code\": person_code,\n",
    "                \"text_segments\": text_count,\n",
    "                \"audio_files\": audio_count,\n",
    "                \"gap\": gap,\n",
    "                \"flag_for_review\": gap > threshold\n",
    "            })\n",
    "    \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"file\": json_file,\n",
    "                \"person_code\": \"N/A\",\n",
    "                \"text_segments\": -1,\n",
    "                \"audio_files\": -1,\n",
    "                \"gap\": -1,\n",
    "                \"flag_for_review\": True,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n SAVE: {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4022e7-ee07-41b7-b14e-ee13e658ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FOLDER = Stroke_OUTPUT\n",
    "LABEL_FOLDER = Stroke_LABEL\n",
    "\n",
    "result_df = analyze_by_count_only(AUDIO_FOLDER, LABEL_FOLDER, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce788c-da66-4401-9302-20447ea80a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_review_target_list(csv_path, save_list_path=\"review_targets_VAD_Stroke.txt\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    review_targets = df[df[\"flag_for_review\"] == True][\"person_code\"].tolist()\n",
    "\n",
    "    with open(save_list_path, 'w', encoding='utf-8') as f:\n",
    "        for code in review_targets:\n",
    "            f.write(code + '\\n')\n",
    "\n",
    "    print(f\"üö© person_code {len(review_targets)} saved: {save_list_path}\")\n",
    "    return review_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1c9a6-2f19-4e28-85af-5a23f53d9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_review_target_list(\"review_targets_VAD_Stroke.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffcaa4-02b4-4b16-a713-b8258aa05e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete preprocessed audio files for file names that do not match 1:1\n",
    "# Delete after checking for existence\n",
    "\n",
    "import os\n",
    "\n",
    "def delete_audio_files_by_person_code(audio_folder, review_list):\n",
    "    deleted_files = []\n",
    "    missing_files = []\n",
    "\n",
    "    for file in os.listdir(audio_folder):\n",
    "        if not file.endswith(\".wav\"):\n",
    "            continue\n",
    "        for code in review_list:\n",
    "            pattern = f\"output_PN_{code}_\"\n",
    "            if file.startswith(pattern):\n",
    "                file_path = os.path.join(audio_folder, file)\n",
    "                if os.path.exists(file_path):\n",
    "                    os.remove(file_path)\n",
    "                    deleted_files.append(file)\n",
    "                else:\n",
    "                    print(f\"Fail Delete (File not exist): {file_path}\")\n",
    "                    missing_files.append(file)\n",
    "\n",
    "    print(f\"Delete {len(deleted_files)} files.\")\n",
    "    if missing_files:\n",
    "        print(f\" Can't delete {len(missing_files)} files.\")\n",
    "    \n",
    "    return deleted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6213a-71b9-4b55-9e35-4cdc5625bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted = delete_audio_files_by_person_code(AUDIO_FOLDER, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc556c6b-856f-4ddc-aade-67936c203529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second preprocessing for deleted audio files\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "\n",
    "# RMS based VAD\n",
    "def vad_segment_by_energy(audio_segment, frame_ms, silence_duration_sec, alpha):\n",
    "    frame_len = frame_ms\n",
    "    total_len = len(audio_segment)\n",
    "    energy_values = []\n",
    "\n",
    "    for i in range(0, total_len, frame_len):\n",
    "        frame = audio_segment[i:i + frame_len]\n",
    "        energy_values.append(frame.rms)\n",
    "\n",
    "    mean_energy = sum(energy_values) / len(energy_values)\n",
    "    threshold = mean_energy * alpha\n",
    "    silence_flags = [rms < threshold for rms in energy_values]\n",
    "\n",
    "    frame_duration_sec = frame_ms / 1000\n",
    "    min_silence_frames = int(silence_duration_sec / frame_duration_sec)\n",
    "\n",
    "    segments = []\n",
    "    is_silent = False\n",
    "    start = 0\n",
    "\n",
    "    for idx, silent in enumerate(silence_flags):\n",
    "        if not is_silent and silent:\n",
    "            silence_run = silence_flags[idx:idx + min_silence_frames]\n",
    "            if len(silence_run) == min_silence_frames and all(silence_run):\n",
    "                end = idx * frame_len\n",
    "                if end - start > 0:\n",
    "                    segments.append((start, end))\n",
    "                is_silent = True\n",
    "        elif is_silent and not silent:\n",
    "            start = idx * frame_len\n",
    "            is_silent = False\n",
    "\n",
    "    if not is_silent and start < total_len:\n",
    "        segments.append((start, total_len))\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Process only target person_code\n",
    "def extract_vad_segments_by_review_targets(Stroke_audio_folder, Stroke_output_base_dir, review_target_codes, frame_ms, silence_duration_sec, alpha):\n",
    "    Stroke_audio_files = glob.glob(os.path.join(Stroke_audio_folder, \"*.wav\"))\n",
    "\n",
    "    if not os.path.exists(Stroke_output_base_dir):\n",
    "        os.makedirs(Stroke_output_base_dir)\n",
    "\n",
    "    for Stroke_audio_file in tqdm(Stroke_audio_files, desc=\"Preprocessing VAD file with segment gap\"):\n",
    "        Stroke_base_filename = os.path.basename(Stroke_audio_file)\n",
    "\n",
    "        match = re.match(r\"ID-\\d{2}-\\d{2}-N-(.+)\\.wav\", Stroke_base_filename)\n",
    "        if not match:\n",
    "            print(f\"Regular expression matching failed: {Stroke_base_filename}\")\n",
    "            continue\n",
    "\n",
    "        person_code = match.group(1)\n",
    "\n",
    "        if person_code not in review_target_codes:\n",
    "            continue\n",
    "\n",
    "        # Load audio\n",
    "        if not os.path.exists(Stroke_audio_file):\n",
    "            print(f\"File not exist: {Stroke_audio_file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            Stroke_audio = AudioSegment.from_file(Stroke_audio_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Fail pre-processing: {Stroke_base_filename} - {e}\")\n",
    "            continue\n",
    "\n",
    "        # Split Silence/non-Silence part\n",
    "        segments = vad_segment_by_energy(Stroke_audio, frame_ms, silence_duration_sec, alpha)\n",
    "\n",
    "        if not segments:\n",
    "            print(f\"failed VAD: {Stroke_base_filename}\")\n",
    "            continue\n",
    "\n",
    "        # Save segment\n",
    "        for i, (start, end) in enumerate(segments):\n",
    "            segment = Stroke_audio[start:end]\n",
    "            Stroke_output_filename = f\"output_PN_{person_code}_{i}.wav\"\n",
    "            Stroke_output_path = os.path.join(Stroke_output_base_dir, Stroke_output_filename)\n",
    "            segment.export(Stroke_output_path, format=\"wav\")\n",
    "            print(f\"‚úÖ {Stroke_base_filename} ‚Üí Segment {i}: {start / 1000:.2f}s ~ {end / 1000:.2f}s ‚Üí {Stroke_output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad027af3-8f2f-40c1-97ae-2ed097f4dd94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the list of person_codes to be preprocessed\n",
    "\n",
    "with open(\"review_targets_VAD_Stroke.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    review_target_codes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "Stroke_audio_folder = Stroke_AUDIO\n",
    "Stroke_output_base_dir = Stroke_OUTPUT\n",
    "\n",
    "extract_vad_segments_by_review_targets(\n",
    "    Stroke_audio_folder,\n",
    "    Stroke_output_base_dir,\n",
    "    review_target_codes,\n",
    "    frame_ms=600,\n",
    "    silence_duration_sec=3,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204a828-ab7a-404d-961f-8cefef545a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of the number of differences between voice-labeling\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_text_segment_count(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    transcript = str(data[\"Transcript\"]).strip()\n",
    "\n",
    "    if \"/\" in transcript:\n",
    "        segments = transcript.split(\"/\")\n",
    "    elif re.search(r\"[\\.?!]\", transcript):\n",
    "        segments = re.split(r\"[\\.?!]\", transcript)\n",
    "    else:\n",
    "        segments = transcript.split()\n",
    "\n",
    "    segments = [s.strip() for s in segments if s.strip()]\n",
    "    return len(segments)\n",
    "\n",
    "def count_audio_files(audio_folder, person_code):\n",
    "    prefix = f\"output_PN_{person_code}_\"\n",
    "    return len([\n",
    "        f for f in os.listdir(audio_folder)\n",
    "        if f.endswith(\".wav\") and f.startswith(prefix)\n",
    "    ])\n",
    "\n",
    "def analyze_by_count_only(audio_folder, label_folder, output_csv=\"review_targets_VAD_Stroke_v2.csv\", threshold=0):\n",
    "    results = []\n",
    "\n",
    "    for json_file in sorted(os.listdir(label_folder)):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "    \n",
    "        json_path = os.path.join(label_folder, json_file)\n",
    "    \n",
    "        try:\n",
    "            match = re.match(r\"ID-\\d{2}-\\d{2}-N-(.+)\\.json\", json_file)\n",
    "            if not match:\n",
    "                raise ValueError(\"Failed to extract person_code from file name\")\n",
    "            person_code = match.group(1)\n",
    "    \n",
    "            text_count = get_text_segment_count(json_path)\n",
    "            audio_count = count_audio_files(audio_folder, person_code)\n",
    "            gap = abs(text_count - audio_count)\n",
    "    \n",
    "            results.append({\n",
    "                \"file\": json_file,\n",
    "                \"person_code\": person_code,\n",
    "                \"text_segments\": text_count,\n",
    "                \"audio_files\": audio_count,\n",
    "                \"gap\": gap,\n",
    "                \"flag_for_review\": gap > threshold\n",
    "            })\n",
    "    \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"file\": json_file,\n",
    "                \"person_code\": \"N/A\",\n",
    "                \"text_segments\": -1,\n",
    "                \"audio_files\": -1,\n",
    "                \"gap\": -1,\n",
    "                \"flag_for_review\": True,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n Save: {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92009aaf-dba5-44da-a62a-d7c05ba067e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FOLDER = Stroke_OUTPUT\n",
    "LABEL_FOLDER = Stroke_LABEL\n",
    "\n",
    "result_df = analyze_by_count_only(AUDIO_FOLDER, LABEL_FOLDER, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712e153-61d8-421b-a507-1c763a5ee492",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['flag_for_review'] == True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbf975-7f94-49aa-b2de-3fb83d052c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def rename_audio_files_sequentially(Stroke_OUTPUT):\n",
    "    pattern = re.compile(r\"output_PN_(.+)_(\\d+)\\.wav\")\n",
    "\n",
    "    person_files = {}\n",
    "    for filename in os.listdir(Stroke_OUTPUT):\n",
    "        if not filename.endswith(\".wav\"):\n",
    "            continue\n",
    "\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            person_code = match.group(1)\n",
    "            index = int(match.group(2))\n",
    "            if person_code not in person_files:\n",
    "                person_files[person_code] = []\n",
    "            person_files[person_code].append((index, filename))\n",
    "\n",
    "    for person_code, files in person_files.items():\n",
    "        files.sort()\n",
    "        for new_index, (old_index, old_filename) in enumerate(files):\n",
    "            new_filename = f\"output_PN_{person_code}_{new_index}.wav\"\n",
    "            old_path = os.path.join(Stroke_OUTPUT, old_filename)\n",
    "            new_path = os.path.join(Stroke_OUTPUT, new_filename)\n",
    "\n",
    "            if old_filename != new_filename:\n",
    "                print(f\"Renaming: {old_filename} ‚Üí {new_filename}\")\n",
    "                os.rename(old_path, new_path)\n",
    "\n",
    "rename_audio_files_sequentially(Stroke_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032b054-e026-4047-88da-b0cba30f332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Stroke_text_df_list = []\n",
    "\n",
    "for i in range(len(os.listdir(Stroke_LABEL))):\n",
    "    Stroke_label_file = os.path.join(Stroke_LABEL, sorted(os.listdir(Stroke_LABEL))[i])\n",
    "    \n",
    "    Stroke_meta = pd.read_json(Stroke_label_file, orient='columns')\n",
    "    Stroke_transcript = str(Stroke_meta['Transcript'].iloc[0]).strip()\n",
    "\n",
    "    if \"/\" in Stroke_transcript:\n",
    "        Stroke_segments = Stroke_transcript.split(\"/\")\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "\n",
    "    elif re.search(r\"[\\.?!]\", Stroke_transcript):\n",
    "        Stroke_segments = re.split(r\"[\\.?!]\", Stroke_transcript)\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "\n",
    "    else:\n",
    "        Stroke_segments = Stroke_transcript.split()\n",
    "        Stroke_segments = [s.strip() for s in Stroke_segments if s.strip()]\n",
    "\n",
    "    if Stroke_segments:\n",
    "        Stroke_df = pd.DataFrame(Stroke_segments, columns=['text'])\n",
    "        Stroke_text_df_list.append(Stroke_df)\n",
    "\n",
    "Stroke_text_df = pd.concat(Stroke_text_df_list, axis=0, ignore_index=True)\n",
    "\n",
    "print(Stroke_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7e006-1d5a-446a-baf5-9ff89f59a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT = os.path.join(Stroke_OUTPUT)\n",
    "\n",
    "print(\"Audio File Count: \", len(os.listdir(SEGMENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d74e7-0031-41bb-8157-e48e686ca584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Text data output folder\n",
    "\n",
    "TEXT_OUTPUT_BASE = BASE_PATH / \"Text_Preprocessed\"\n",
    "Stroke_TEXT_OUTPUT = TEXT_OUTPUT_BASE / \"Stroke_dataset\"\n",
    "\n",
    "Stroke_TEXT_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Stroke ‚Üí\", Stroke_TEXT_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ce4de-0f6c-4aea-9d33-8f7f1b1be032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Stroke_text_df_list = []\n",
    "\n",
    "for filename in sorted(os.listdir(Stroke_LABEL)):\n",
    "    if not filename.endswith(\".json\"):\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(Stroke_LABEL, filename)\n",
    "    meta = pd.read_json(file_path, orient='columns')\n",
    "    transcript = str(meta['Transcript'].iloc[0]).strip()\n",
    "\n",
    "    if \"/\" in transcript:\n",
    "        segments = transcript.split(\"/\")\n",
    "    elif re.search(r\"[\\.?!]\", transcript):\n",
    "        segments = re.split(r\"[\\.?!]\", transcript)\n",
    "    else:\n",
    "        segments = transcript.split()\n",
    "\n",
    "    segments = [s.strip() for s in segments if s.strip()]\n",
    "\n",
    "    if segments:\n",
    "        df = pd.DataFrame({\n",
    "            'filename': [filename] * len(segments),\n",
    "            'text': segments\n",
    "        })\n",
    "        Stroke_text_df_list.append(df)\n",
    "\n",
    "Stroke_text_df = pd.concat(Stroke_text_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e63a93-49c1-4ade-b425-b216322af181",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_counter = {}\n",
    "\n",
    "for i in range(len(Stroke_text_df)):\n",
    "    row = Stroke_text_df.iloc[i]\n",
    "\n",
    "    full_name = os.path.splitext(row['filename'])[0]  # \"output_PN_AJH-01-01-F-45-SU_0\"\n",
    "\n",
    "    match = re.match(r'ID-\\d{2}-\\d{2}-N-(.+)', full_name)\n",
    "    \n",
    "    if match:\n",
    "        person_code = match.group(1)  # ex: AJH-01-01-F-45-SU\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Code pattern does not match: {full_name}\")\n",
    "        continue\n",
    "\n",
    "    count = filename_counter.get(person_code, 0)\n",
    "    filename_counter[person_code] = count + 1\n",
    "\n",
    "    new_filename = f\"output_PN_{person_code}_{count}.txt\"\n",
    "    output_path = Stroke_TEXT_OUTPUT / new_filename\n",
    "\n",
    "    cleaned_text = re.sub(r\"[+\\*\\(\\)\\?!,\\.~\\-']\", \"\", row['text'])\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(cleaned_text)\n",
    "\n",
    "print(\"‚úÖ TextData is Saved:\", Stroke_TEXT_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
